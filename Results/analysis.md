# Analysis
Recall scores are the most important metric for disease identification. False negatives are far more detrimental than false positives when identifying diseased crops. 
The precision, recall F1  and accuracy scores for each of the models are within their respective subfolders under Results (highlighted fields are disease classes).

  For most architectures, the POV combined models did not perform better than their counterparts that were trained on the full set of data. Average recall scores for all classes and overall accuracy were lower in the POV combined models for the ResNet50, VGG19 and GoogleNet architectures. Even when isolating just the disease classes, models trained with these architectures do not appear to have benefited from being pretrained with POV -specific datasets.
  
  For every set of models (except those with VGG19 architectures), the recall scores for the Peach Anarsia Lineatella class were higher in the Combined POV models. This may be due to the fact that, at a glance, the aerial multispectral images in the Peach dataset appeared to have few features in common with their ground counterparts. The models trained on the aerial datasets before combining them into a unified model were able to better learn the features of the Peach Anarsia Lineatella afflicted trees from the aerial POV without the influence of their ground counterparts. 
  
  The model set with AlexNet architectures performed similarly on average for precision, recall, F1 scores and accuracy. When focusing on disease classes, the combined POV model had lower recall scores in 4 out of 6 classes.
  
  The only Combined POV model that performed better than its same architecture counterpart was the MobileNet Small model. Average recall and precision scores were higher in the Combined POV than its counterpart that was trained on the full image setâ€™s training split. Among disease classes, the combined POV model had higher recall scores in 5 out of 6 cases. This may be due to the resource-aware scaling and layer-wise optimization in MobileNet. MobileNet v3 uses automated Neural Architecture Search to optimize the configuration of layer widths and depths for maximum accuracy and efficiency. (A. Howard et al., 2019) This results in layers that differ in their ability to gather higher, intermediate and lower scale features. This scaling is not necessarily a linear relationship based on layer depth. The UAV images from the peach, cherry and banana datasets were from such a distance that the ability to extract high-level features may have been more important. 
